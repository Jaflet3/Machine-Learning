{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBFc2f7FsAvP",
        "outputId": "ff55aeef-6426-4a38-f3c7-6a54a0c99be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: exit\n",
            "Bot: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Simple chatbot function\n",
        "def chatbot_response(user_input):\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    if \"hello\" in user_input:\n",
        "        return \"Hi there!\"\n",
        "    elif \"your name\" in user_input:\n",
        "        return \"I'm a simple chatbot.\"\n",
        "    elif \"how are you\" in user_input:\n",
        "        return \"I'm doing great, thanks for asking!\"\n",
        "    elif \"bye\" in user_input:\n",
        "        return \"Goodbye!\"\n",
        "    else:\n",
        "        return \"Sorry, I don't understand that.\"\n",
        "\n",
        "# Chat loop\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(\"Bot:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n"
      ],
      "metadata": {
        "id": "9WYPPVgwsd6Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Simple rule-based response function\n",
        "def get_answer(user_input, chat_history):\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "\n",
        "\n",
        "# Simple rule-based response function\n",
        "def get_answer(user_input, chat_history):\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    # Simple rule-based answers\n",
        "    if \"hello\" in user_input:\n",
        "        answer = \"Hello!\"\n",
        "    elif \"what is your name\" in user_input:\n",
        "        answer = \"I'm Jaflet Evangeline.\"\n",
        "    elif \"how are you\" in user_input:\n",
        "        answer = \"I'm doing well\"\n",
        "    elif \"where you were located\" in user_input:  # âœ… lowercase\n",
        "        answer = \"Aruppukottai\"\n",
        "    else:\n",
        "        answer = \"Sorry, I don't understand that yet.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    chat_history.append((user_input, answer))\n",
        "    return \"\", chat_history\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot_ui = gr.Chatbot()\n",
        "    user_input = gr.Textbox(placeholder=\"Ask me anything...\", label=\"Your Question\")\n",
        "    state = gr.State([])\n",
        "\n",
        "    user_input.submit(get_answer,[user_input, state], [user_input, chatbot_ui])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "w-jp0EMbwb3K",
        "outputId": "4777a272-996c-4fd5-df19-adcbda2e361f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-2153381039>:33: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot_ui = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e540e487755bbb019a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e540e487755bbb019a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}